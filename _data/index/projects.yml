# projects section data
# If you don't have language feature(language.yml is empty), ignore "i18n" items
# Suggest projects' img be located at '/static/assets/img/landing', and edit following img items.
- name: End-To-End-Self-Supervised-SLAM
  url: https://www.linkedin.com/in/ivan-alberico-5793581a4/detail/treasury/education:673317205/?entityUrn=urn%3Ali%3Afsd_profileTreasuryMedia%3A(ACoAAC-_8i0B0Z25y7ZE-CHu8YKTpMxpcMLKy48%2C1635473655417)&section=education%3A673317205&treasuryCount=1
  i18n: jalpc
  gh_user: ivanalberico
  repo: End-To-End-Self-Supervised-SLAM
  img: /static/assets/img/landing/projects_imgs/end2endSSS.png
  desc: 3D Vision course project, ETH Z端rich (Spring 2021). The project was supervised by Google Research Interns. The goal of this project is to use an online adaptation module to overcome the domain shift  issue in dense reconstruction and build a fully differentiable SLAM pipeline that can be optimized End-2-End. We propose to combine the SLAM framework of GradSLAM with a self-supervised depth prediction network, to optimize a SLAM pipeline for real-time dense reconstruction on totally unseen scenes.

- name: Multi-task learning for semantics and depth
  i18n: jalpc
  gh_user: ivanalberico
  repo: Deep-Learning-for-Autonomous-Driving-ETH
  img: /static/assets/img/landing/projects_imgs/multi-task-learning.png
  desc: Deep Learning for Autonomous Driving course project, ETH Z端rich (Spring 2021). The goal of the project is to build Multi-Task Learning (MTL) architectures for dense prediction tasks, i.e. semantic segmentation and monocular depth estimation in autonomous driving scenes, exploiting joint architectures, branched architectures, and task distillation.

- name: 3D Object Detection from Lidar Point Clouds
  i18n: jalpc
  gh_user: ivanalberico
  repo: Deep-Learning-for-Autonomous-Driving-ETH
  img: /static/assets/img/landing/projects_imgs/3D_object_detection.png
  desc: Deep Learning for Autonomous Driving course project, ETH Z端rich (Spring 2021). The goal of the project is to build a 2-stage 3D object detector to detect vehicles in autonomous driving scenes, i.e. drawing 3D bounding boxes around each vehicle. Irregular 3D point cloud data are exploited to detect vehicles.

- name: SkaterBlob game on Unity3D
  i18n: jalpc
  gh_user: ivanalberico
  repo: Virtual-Reality1-ETH-SkaterBlobGame
  img: /static/assets/img/landing/projects_imgs/skaterBlob.png
  desc: Virtual Reality I course project, ETH Z端rich (Spring 2021). The project consists in the implementation of a skateboarding game using Unity3D and Blender.
